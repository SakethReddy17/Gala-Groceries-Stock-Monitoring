{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuFoWoVU3lk4"
      },
      "outputs": [],
      "source": [
        "# ------- BEFORE STARTING - SOME BASIC TIPS\n",
        "# You can add a comment within a Python file by using a hashtag '#'\n",
        "# Anything that comes after the hashtag on the same line, will be considered\n",
        "# a comment and won't be executed as code by the Python interpreter.\n",
        "\n",
        "# --- 1) IMPORTING PACKAGES\n",
        "# The first thing you should always do in a Python file is to import any\n",
        "# packages that you will need within the file. This should always go at the top\n",
        "# of the file\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2) DEFINE GLOBAL CONSTANTS\n",
        "# Constants are variables that should remain the same througout the entire running\n",
        "# of the module. You should define these after the imports at the top of the file.\n",
        "# You should give global constants a name and ensure that they are in all upper\n",
        "# case, such as: UPPER_CASE\n",
        "\n",
        "# K is used to define the number of folds that will be used for cross-validation\n",
        "K = 10\n",
        "\n",
        "# Split defines the % of data that will be used in the training sample\n",
        "# 1 - SPLIT = the % used for testing\n",
        "SPLIT = 0.75\n"
      ],
      "metadata": {
        "id": "jZkYlTZ4pVah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1) IMPORTING PACKAGES\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- 2) DEFINE GLOBAL CONSTANTS\n",
        "K = 10\n",
        "SPLIT = 0.75\n",
        "\n",
        "# --- 3) ALGORITHM CODE\n",
        "\n",
        "# Load data\n",
        "def load_data(path: str = \"/content/sales.csv\"):\n",
        "    \"\"\"\n",
        "    This function takes a path string to a CSV file and loads it into\n",
        "    a Pandas DataFrame.\n",
        "\n",
        "    :param      path (optional): str, relative path of the CSV file\n",
        "\n",
        "    :return     df: pd.DataFrame\n",
        "    \"\"\"\n",
        "    print(\"Loading data...\")\n",
        "    df = pd.read_csv(f\"{path}\")\n",
        "    df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "    print(\"Data loaded successfully\")\n",
        "    return df\n",
        "\n",
        "# Create target variable and predictor variables\n",
        "def create_target_and_predictors(\n",
        "    data: pd.DataFrame = None,\n",
        "    target: str = \"estimated_stock_pct\"\n",
        "):\n",
        "    \"\"\"\n",
        "    This function takes in a Pandas DataFrame and splits the columns\n",
        "    into a target column and a set of predictor variables, i.e. X & y.\n",
        "    These two splits of the data will be used to train a supervised\n",
        "    machine learning model.\n",
        "\n",
        "    :param      data: pd.DataFrame, dataframe containing data for the\n",
        "                      model\n",
        "    :param      target: str (optional), target variable that you want to predict\n",
        "\n",
        "    :return     X: pd.DataFrame\n",
        "                y: pd.Series\n",
        "    \"\"\"\n",
        "    print(\"Creating target and predictor variables...\")\n",
        "    # Check to see if the target variable is present in the data\n",
        "    #if target not in data.columns:\n",
        "      #  raise Exception(f\"Target: {target} is not present in the data\")\n",
        "\n",
        "    #X = data.drop(columns=[target])\n",
        "    #y = data[target]\n",
        "    #print(\"Target and predictors created successfully\")\n",
        "    #return y\n",
        "\n",
        "# Train algorithm\n",
        "def train_algorithm_with_cross_validation(\n",
        "    X: pd.DataFrame = None,\n",
        "    y: pd.Series = None\n",
        "):\n",
        "    \"\"\"\n",
        "    This function takes the predictor and target variables and\n",
        "    trains a Random Forest Regressor model across K folds. Using\n",
        "    cross-validation, performance metrics will be output for each\n",
        "    fold during training.\n",
        "\n",
        "    :param      X: pd.DataFrame, predictor variables\n",
        "    :param      y: pd.Series, target variable\n",
        "\n",
        "        \"\"\"\n",
        "    X:pd.DataFrame[predictor variables]\n",
        "        print(\"Starting cross-validation...\")\n",
        "        # Create a list that will store the accuracies of each fold\n",
        "    accuracy = []\n",
        "\n",
        "    # Enter a loop to run K folds of cross-validation\n",
        "    for fold in range(0, K):\n",
        "        print(f\"Processing fold {fold + 1}...\")\n",
        "        # Instantiate algorithm and scaler\n",
        "        model = RandomForestRegressor()\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        # Create training and test samples\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=SPLIT, random_state=42)\n",
        "\n",
        "        # Scale X data, we scale the data because it helps the algorithm to converge\n",
        "        # and helps the algorithm to not be greedy with large values\n",
        "        scaler.fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Train model\n",
        "        trained_model = model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate predictions on test sample\n",
        "        y_pred = trained_model.predict(X_test)\n",
        "\n",
        "        # Compute accuracy, using mean absolute error\n",
        "        mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
        "        accuracy.append(mae)\n",
        "        print(f\"Fold {fold + 1}: MAE = {mae:.3f}\")\n",
        "\n",
        "    # Finish by computing the average MAE across all folds\n",
        "    print(f\"Average MAE: {(sum(accuracy) / len(accuracy)):.2f}\")\n",
        "\n",
        "# --- 4) MAIN FUNCTION\n",
        "\n",
        "def run():\n",
        "    print(\"Running the pipeline...\")\n",
        "    df = load_data(\"/content/sales.csv\")\n",
        "    #X, y = create_target_and_predictors(data=df)\n",
        "    train_algorithm_with_cross_validation(X=X, y=y)\n",
        "    print(\"Pipeline executed successfully\")\n",
        "run()"
      ],
      "metadata": {
        "id": "9u4hMS9TpY2n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "19d23b2c-f3b7-4b87-8ec8-c297248eefa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-24-2075f51c7069>, line 74)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-2075f51c7069>\"\u001b[0;36m, line \u001b[0;32m74\u001b[0m\n\u001b[0;31m    X: pd.DataFrame, predictor variables\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------- BEFORE STARTING - SOME BASIC TIPS\n",
        "# You can add a comment within a Python file by using a hashtag '#'\n",
        "# Anything that comes after the hashtag on the same line, will be considered\n",
        "# a comment and won't be executed as code by the Python interpreter.\n",
        "\n",
        "# --- 1) IMPORTING PACKAGES\n",
        "# The first thing you should always do in a Python file is to import any\n",
        "# packages that you will need within the file. This should always go at the top\n",
        "# of the file\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# --- 2) DEFINE GLOBAL CONSTANTS\n",
        "# Constants are variables that should remain the same througout the entire running\n",
        "# of the module. You should define these after the imports at the top of the file.\n",
        "# You should give global constants a name and ensure that they are in all upper\n",
        "# case, such as: UPPER_CASE\n",
        "\n",
        "# K is used to define the number of folds that will be used for cross-validation\n",
        "K = 10\n",
        "\n",
        "# Split defines the % of data that will be used in the training sample\n",
        "# 1 - SPLIT = the % used for testing\n",
        "SPLIT = 0.75\n",
        "\n",
        "# --- 3) ALGORITHM CODE\n",
        "# Next, we should write our code that will be executed when a model needs to be\n",
        "# trained. There are many ways to structure this code and it is your choice\n",
        "# how you wish to do this. The code in the 'module_helper.py' file will break\n",
        "# the code down into independent functions, which is 1 option.\n",
        "# Include your algorithm code in this section below:\n",
        "\n",
        "# Load data\n",
        "def load_data(path: str = \"/content/sales.csv\"):\n",
        "    \"\"\"\n",
        "    This function takes a path string to a CSV file and loads it into\n",
        "    a Pandas DataFrame.\n",
        "\n",
        "    :param      path (optional): str, relative path of the CSV file\n",
        "\n",
        "    :return     df: pd.DataFrame\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(f\"{path}\")\n",
        "    df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "    return df\n",
        "\n",
        "# Create target variable and predictor variables\n",
        "def create_target_and_predictors(\n",
        "    data: pd.DataFrame = None,\n",
        "    target: str = \"estimated_stock_pct\"\n",
        "):\n",
        "    \"\"\"\n",
        "    This function takes in a Pandas DataFrame and splits the columns\n",
        "    into a target column and a set of predictor variables, i.e. X & y.\n",
        "    These two splits of the data will be used to train a supervised\n",
        "    machine learning model.\n",
        "\n",
        "    :param      data: pd.DataFrame, dataframe containing data for the\n",
        "                      model\n",
        "    :param      target: str (optional), target variable that you want to predict\n",
        "\n",
        "    :return     X: pd.DataFrame\n",
        "                y: pd.Series\n",
        "    \"\"\"\n",
        "\n",
        "    # Check to see if the target variable is present in the data\n",
        "    if target not in data.columns:\n",
        "        raise Exception(f\"Target: {target} is not present in the data\")\n",
        "\n",
        "    X = data.drop(columns=[target])\n",
        "    y = data[target]\n",
        "    return X, y\n",
        "\n",
        "# Train algorithm\n",
        "def train_algorithm_with_cross_validation(\n",
        "    X: pd.DataFrame = None,\n",
        "    y: pd.Series = None\n",
        "):\n",
        "    \"\"\"\n",
        "    This function takes the predictor and target variables and\n",
        "    trains a Random Forest Regressor model across K folds. Using\n",
        "    cross-validation, performance metrics will be output for each\n",
        "    fold during training.\n",
        "\n",
        "    :param      X: pd.DataFrame, predictor variables\n",
        "    :param      y: pd.Series, target variable\n",
        "\n",
        "    :return\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a list that will store the accuracies of each fold\n",
        "    accuracy = []\n",
        "\n",
        "    # Enter a loop to run K folds of cross-validation\n",
        "    for fold in range(0, K):\n",
        "\n",
        "        # Instantiate algorithm and scaler\n",
        "        model = RandomForestRegressor()\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        # Create training and test samples\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=SPLIT, random_state=42)\n",
        "\n",
        "        # Scale X data, we scale the data because it helps the algorithm to converge\n",
        "        # and helps the algorithm to not be greedy with large values\n",
        "        scaler.fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Train model\n",
        "        trained_model = model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate predictions on test sample\n",
        "        y_pred = trained_model.predict(X_test)\n",
        "\n",
        "        # Compute accuracy, using mean absolute error\n",
        "        mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
        "        accuracy.append(mae)\n",
        "        print(f\"Fold {fold + 1}: MAE = {mae:.3f}\")\n",
        "\n",
        "    # Finish by computing the average MAE across all folds\n",
        "    print(f\"Average MAE: {(sum(accuracy) / len(accuracy)):.2f}\")\n",
        "    # --- 4) MAIN FUNCTION\n",
        "# Your algorithm code should contain modular code that can be run independently.\n",
        "# You may want to include a final function that ties everything together, to allow\n",
        "# the entire pipeline of loading the data and training the algorithm to be run all\n",
        "# at once\n",
        "\n",
        "# Execute training pipeline\n",
        "def run():\n",
        "    \"\"\"\n",
        "    This function executes the training pipeline of loading the prepared\n",
        "    dataset from a CSV file and training the machine learning model\n",
        "\n",
        "    :param\n",
        "\n",
        "    :return\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the data first\n",
        "    df = load_data(\"/content/sales.csv\")\n",
        "\n",
        "    # Now split the data into predictors and target variables\n",
        "    X, y = create_target_and_predictors(data=df)\n",
        "\n",
        "    # Finally, train the machine learning model\n",
        "    train_algorithm_with_cross_validation(X=X, y=y)"
      ],
      "metadata": {
        "id": "HJfifzBS8RWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4) MAIN FUNCTION\n",
        "# Your algorithm code should contain modular code that can be run independently.\n",
        "# You may want to include a final function that ties everything together, to allow\n",
        "# the entire pipeline of loading the data and training the algorithm to be run all\n",
        "# at once\n",
        "\n",
        "# Execute training pipeline\n",
        "def run():\n",
        "    \"\"\"\n",
        "    This function executes the training pipeline of loading the prepared\n",
        "    dataset from a CSV file and training the machine learning model\n",
        "\n",
        "    :param\n",
        "\n",
        "    :return\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the data first\n",
        "    df = load_data(\"/content/sales.csv\")\n",
        "\n",
        "    # Now split the data into predictors and target variables\n",
        "    X, y = create_target_and_predictors(data=df)\n",
        "\n",
        "    # Finally, train the machine learning model\n",
        "    train_algorithm_with_cross_validation(X=X, y=y)"
      ],
      "metadata": {
        "id": "o9w_Mh5gpr8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- 2) DEFINE GLOBAL CONSTANTS\n",
        "K = 10\n",
        "SPLIT = 0.75\n",
        "\n",
        "# --- 3) ALGORITHM CODE\n",
        "\n",
        "# Load data\n",
        "def load_data(path: str = \"/content/sales.csv\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    This function takes a path string to a CSV file and loads it into\n",
        "    a Pandas DataFrame.\n",
        "\n",
        "    :param      path (optional): str, relative path of the CSV file\n",
        "\n",
        "    :return     df: pd.DataFrame\n",
        "    \"\"\"\n",
        "    print(\"Loading data...\")\n",
        "    df = pd.read_csv(f\"{path}\")\n",
        "    df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "    print(\"Data loaded successfully\")\n",
        "    return df\n",
        "\n",
        "# Create target variable and predictor variables\n",
        "def create_target_and_predictors(\n",
        "    data: pd.DataFrame,\n",
        "    target: str = \"category\"\n",
        "):\n",
        "    \"\"\"\n",
        "    This function takes in a Pandas DataFrame and splits the columns\n",
        "    into a target column and a set of predictor variables, i.e. X & y.\n",
        "    These two splits of the data will be used to train a supervised\n",
        "    machine learning model.\n",
        "\n",
        "    :param      data: pd.DataFrame, dataframe containing data for the\n",
        "                      model\n",
        "    :param      target: str (optional), target variable that you want to predict\n",
        "\n",
        "    :return     X: pd.DataFrame\n",
        "                y: pd.Series\n",
        "    \"\"\"\n",
        "    print(\"Creating target and predictor variables...\")\n",
        "    # Check to see if the target variable is present in the data\n",
        "    if target not in data.columns:\n",
        "        raise Exception(f\"Target: {target} is not present in the data\")\n",
        "\n",
        "    X = data.drop(columns=[target])\n",
        "    y = data[target]\n",
        "    print(\"Target and predictors created successfully\")\n",
        "    return X, y\n",
        "\n",
        "# Train algorithm\n",
        "def train_algorithm_with_cross_validation(\n",
        "    X: pd.DataFrame,\n",
        "    y: pd.Series\n",
        ") :\n",
        "    \"\"\"\n",
        "    This function takes the predictor and target variables and\n",
        "    trains a Random Forest Regressor model across K folds. Using\n",
        "    cross-validation, performance metrics will be output for each\n",
        "    fold during training.\n",
        "\n",
        "    :param      X: pd.DataFrame, predictor variables\n",
        "    :param      y: pd.Series, target variable\n",
        "\n",
        "    :return     None\n",
        "    \"\"\"\n",
        "    print(\"Starting cross-validation...\")\n",
        "    # Create a list that will store the accuracies of each fold\n",
        "    accuracy = []\n",
        "\n",
        "    # Enter a loop to run K folds of cross-validation\n",
        "    for fold in range(0, K):\n",
        "        print(f\"Processing fold {fold + 1}...\")\n",
        "        # Instantiate algorithm and scaler\n",
        "        model = RandomForestRegressor()\n",
        "        scaler = StandardScaler()\n",
        "        # Create training and test samples\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=SPLIT, random_state=42)\n",
        "\n",
        "        # Scale X data, we scale the data because it helps the algorithm to converge\n",
        "        # and helps the algorithm to not be greedy with large values\n",
        "\n",
        "X_train = scaler.fit_transform(X)\n",
        "X_test = scaler.transform(X_test)\n",
        "y_train = scaler.fit_transform(y_train)\n",
        "        #X_train = StandardScaler().transform(X_train)\n",
        "       # X_test = StandardScaler().transform(X_test)\n",
        "\n",
        "        # Train model\n",
        "trained_model = model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate predictions on test sample\n",
        "y_pred = trained_model.predict(X_test)\n",
        "\n",
        "        # Compute accuracy, using mean absolute error\n",
        "mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
        "accuracy.append(mae)\n",
        "print(f\"Fold {fold + 1}: MAE = {mae:.3f}\")\n",
        "\n",
        "    # Finish by computing the average MAE across all folds\n",
        "print(f\"Average MAE: {(sum(accuracy) / len(accuracy)):.2f}\")\n",
        "\n",
        "\n",
        "# --- 4) MAIN FUNCTION\n",
        "\n",
        "def run() -> None:\n",
        "    print(\"Running the pipeline...\")\n",
        "    df = load_data(\"/content/sales.csv\")\n",
        "    X, y = create_target_and_predictors(data=df)\n",
        "    train_algorithm_with_cross_validation(X=X, y=y)\n",
        "    print(\"Pipeline executed successfully\")\n",
        "\n",
        "# Call the run function directly\n",
        "run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8pJqbB0cF1gV",
        "outputId": "5f21d3fa-061e-4be7-a0aa-a4433276b484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-649d7b5efabf>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# and helps the algorithm to not be greedy with large values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- 2) DEFINE GLOBAL CONSTANTS\n",
        "K = 10\n",
        "SPLIT = 0.75\n",
        "\n",
        "# --- 3) ALGORITHM CODE\n",
        "\n",
        "# Load data\n",
        "def load_data(path: str = \"/content/sales.csv\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    This function takes a path string to a CSV file and loads it into\n",
        "    a Pandas DataFrame.\n",
        "\n",
        "    :param      path (optional): str, relative path of the CSV file\n",
        "\n",
        "    :return     df: pd.DataFrame\n",
        "    \"\"\"\n",
        "    print(\"Loading data...\")\n",
        "    df = pd.read_csv(f\"{path}\")\n",
        "    df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "    print(\"Data loaded successfully\")\n",
        "    return df\n",
        "\n",
        "# Create target variable and predictor variables\n",
        "def create_target_and_predictors(\n",
        "    data: pd.DataFrame,\n",
        "    target: str = \"category\"\n",
        ") :    \"\"\"\n",
        "    This function takes in a Pandas DataFrame and splits the columns\n",
        "    into a target column and a set of predictor variables, i.e. X & y.\n",
        "    These two splits of the data will be used to train a supervised\n",
        "    machine learning model.\n",
        "\n",
        "    :param      data: pd.DataFrame, dataframe containing data for the\n",
        "                      model\n",
        "    :param      target: str (optional), target variable that you want to predict\n",
        "\n",
        "    :return     X: pd.DataFrame\n",
        "                y: pd.Series\n",
        "    \"\"\"\n",
        "    print(\"Creating target and predictor variables...\")\n",
        "    # Print the columns of the DataFrame\n",
        "    print(\"Data columns:\", data.columns)\n",
        "\n",
        "    # Check to see if the target variable is present in the data\n",
        "    if target not in data.columns:\n",
        "        raise Exception(f\"Target: {target} is not present in the data\")\n",
        "\n",
        "    X = data.drop(columns=[target])\n",
        "    y = data[target]\n",
        "    print(\"Target and predictors created successfully\")\n",
        "    return X, y\n",
        "\n",
        "# Train algorithm\n",
        "def train_algorithm_with_cross_validation(\n",
        "    X: pd.DataFrame,\n",
        "    y: pd.Series\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    This function takes the predictor and target variables and\n",
        "    trains a Random Forest Regressor model across K folds. Using\n",
        "    cross-validation, performance metrics will be output for each\n",
        "    fold during training.\n",
        "\n",
        "    :param      X: pd.DataFrame, predictor variables\n",
        "    :param      y: pd.Series, target variable\n",
        "\n",
        "    :return     None\n",
        "    \"\"\"\n",
        "    print(\"Starting cross-validation...\")\n",
        "    # Create a list that will store the accuracies of each fold\n",
        "    accuracy = []\n",
        "\n",
        "    # Enter a loop to run K folds of cross-validation\n",
        "    for fold in range(0, K):\n",
        "        print(f\"Processing fold {fold + 1}...\")\n",
        "        # Instantiate algorithm and scaler\n",
        "        model = RandomForestRegressor()\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        # Create training and test samples\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=SPLIT, random_state=42)\n",
        "\n",
        "        # Scale X data, we scale the data because it helps the algorithm to converge\n",
        "        # and helps the algorithm to not be greedy with large values\n",
        "        scaler.fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Train model\n",
        "        trained_model = model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate predictions on test sample\n",
        "        y_pred = trained_model.predict(X_test)\n",
        "\n",
        "        # Compute accuracy, using mean absolute error\n",
        "        mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
        "        accuracy.append(mae)\n",
        "        print(f\"Fold {fold + 1}: MAE = {mae:.3f}\")\n",
        "\n",
        "    # Finish by computing the average MAE across all folds\n",
        "    print(f\"Average MAE: {(sum(accuracy) / len(accuracy)):.2f}\")\n",
        "\n",
        "# --- 4) MAIN FUNCTION\n",
        "\n",
        "def run() -> None:\n",
        "    print(\"Running the pipeline...\")\n",
        "    df = load_data(\"/content/sales.csv\")\n",
        "    X, y = create_target_and_predictors(data=df)\n",
        "    train_algorithm_with_cross_validation(X=X, y=y)\n",
        "    print(\"Pipeline executed successfully\")\n",
        "\n",
        "# Call the run function directly\n",
        "run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "x-UiNjlXHkRY",
        "outputId": "ab40b85d-9ed8-48af-81a2-dda2299c0c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-69-01a4376409ac>, line 46)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-69-01a4376409ac>\"\u001b[0;36m, line \u001b[0;32m46\u001b[0m\n\u001b[0;31m    print(\"Creating target and predictor variables...\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- 2) DEFINE GLOBAL CONSTANTS\n",
        "K = 10\n",
        "SPLIT = 0.75\n",
        "\n",
        "# --- 3) ALGORITHM CODE\n",
        "\n",
        "# Load data\n",
        "def load_data(path: str = \"/content/sales.csv\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    This function takes a path string to a CSV file and loads it into\n",
        "    a Pandas DataFrame.\n",
        "\n",
        "    :param      path (optional): str, relative path of the CSV file\n",
        "\n",
        "    :return     df: pd.DataFrame\n",
        "    \"\"\"\n",
        "    print(\"Loading data...\")\n",
        "    df = pd.read_csv(f\"{path}\")\n",
        "    df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "    print(\"Data loaded successfully\")\n",
        "    return df\n",
        "\n",
        "# Create target variable and predictor variables\n",
        "def create_target_and_predictors(\n",
        "    data: pd.DataFrame,\n",
        "    target: str = \"category\"\n",
        "):    # Removed extra indentation here\n",
        "    \"\"\"\n",
        "    This function takes in a Pandas DataFrame and splits the columns\n",
        "    into a target column and a set of predictor variables, i.e. X & y.\n",
        "    These two splits of the data will be used to train a supervised\n",
        "    machine learning model.\n",
        "\n",
        "    :param      data: pd.DataFrame, dataframe containing data for the\n",
        "                      model\n",
        "    :param      target: str (optional), target variable that you want to predict\n",
        "\n",
        "    :return     X: pd.DataFrame\n",
        "                y: pd.Series\n",
        "    \"\"\"\n",
        "    print(\"Creating target and predictor variables...\")\n",
        "    # Print the columns of the DataFrame\n",
        "    print(\"Data columns:\", data.columns)\n",
        "\n",
        "    # Check to see if the target variable is present in the data\n",
        "    if target not in data.columns:\n",
        "        raise Exception(f\"Target: {target} is not present in the data\")\n",
        "\n",
        "    X = data.drop(columns=[target])\n",
        "    y = data[target]\n",
        "    print(\"Target and predictors created successfully\")\n",
        "    return X, y\n",
        "\n",
        "# Train algorithm\n",
        "def train_algorithm_with_cross_validation(\n",
        "    X: pd.DataFrame,\n",
        "    y: pd.Series\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    This function takes the predictor and target variables and\n",
        "    trains a Random Forest Regressor model across K folds. Using\n",
        "    cross-validation, performance metrics will be output for each\n",
        "    fold during training.\n",
        "\n",
        "    :param      X: pd.DataFrame, predictor variables\n",
        "    :param      y: pd.Series, target variable\n",
        "\n",
        "    :return     None\n",
        "    \"\"\"\n",
        "    print(\"Starting cross-validation...\")\n",
        "    # Create a list that will store the accuracies of each fold\n",
        "    accuracy = []\n",
        "\n",
        "    # Enter a loop to run K folds of cross-validation\n",
        "    for fold in range(0, K):\n",
        "        print(f\"Processing fold {fold + 1}...\")\n",
        "        # Instantiate algorithm and scaler\n",
        "        model = RandomForestRegressor()\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        # Create training and test samples\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=SPLIT, random_state=42)\n",
        "\n",
        "        # Scale X data, we scale the data because it helps the algorithm to converge\n",
        "        # and helps the algorithm to not be greedy with large values\n",
        "        scaler.fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Train model\n",
        "        trained_model = model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate predictions on test sample\n",
        "        y_pred = trained_model.predict(X_test)\n",
        "\n",
        "        # Compute accuracy, using mean absolute error\n",
        "        mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
        "        accuracy.append(mae)\n",
        "        print(f\"Fold {fold + 1}: MAE = {mae:.3f}\")\n",
        "\n",
        "    # Finish\n",
        "    # Finish by computing the average MAE across all folds\n",
        "    print(f\"Average MAE: {(sum(accuracy) / len(accuracy)):.2f}\")\n",
        "\n",
        "# --- 4) MAIN FUNCTION\n",
        "\n",
        "def run() -> None:\n",
        "    print(\"Running the pipeline...\")\n",
        "    df = load_data(\"/content/sales.csv\")\n",
        "    X, y = create_target_and_predictors(data=df)\n",
        "    train_algorithm_with_cross_validation(X=X, y=y)\n",
        "    print(\"Pipeline executed successfully\")\n",
        "\n",
        "# Call the run function directly\n",
        "run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "vvmgTRPHPeQQ",
        "outputId": "764fb8b8-32d0-4b12-cdd9-1da510dc4146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running the pipeline...\n",
            "Loading data...\n",
            "Data loaded successfully\n",
            "Creating target and predictor variables...\n",
            "Data columns: Index(['transaction_id', 'timestamp', 'product_id', 'category',\n",
            "       'customer_type', 'unit_price', 'quantity', 'total', 'payment_type'],\n",
            "      dtype='object')\n",
            "Target and predictors created successfully\n",
            "Starting cross-validation...\n",
            "Processing fold 1...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'fcf55ad0-c877-44f5-8c6f-8d00667b5718'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-58323f5c35b8>\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# Call the run function directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-71-58323f5c35b8>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sales.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_target_and_predictors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mtrain_algorithm_with_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline executed successfully\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-58323f5c35b8>\u001b[0m in \u001b[0;36mtrain_algorithm_with_cross_validation\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Scale X data, we scale the data because it helps the algorithm to converge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# and helps the algorithm to not be greedy with large values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         if (\n\u001b[1;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'fcf55ad0-c877-44f5-8c6f-8d00667b5718'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- 2) DEFINE GLOBAL CONSTANTS\n",
        "K = 10\n",
        "SPLIT = 0.75\n",
        "\n",
        "# --- 3) ALGORITHM CODE\n",
        "\n",
        "# Load data\n",
        "def load_data(path: str = \"/content/sales.csv\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    This function takes a path string to a CSV file and loads it into\n",
        "    a Pandas DataFrame.\n",
        "\n",
        "    :param      path (optional): str, relative path of the CSV file\n",
        "\n",
        "    :return     df: pd.DataFrame\n",
        "    \"\"\"\n",
        "    print(\"Loading data...\")\n",
        "    df = pd.read_csv(f\"{path}\")\n",
        "    df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "    print(\"Data loaded successfully\")\n",
        "    return df\n",
        "\n",
        "# Create target variable and predictor variables\n",
        "def create_target_and_predictors(\n",
        "    data: pd.DataFrame,\n",
        "    target: str = \"category\"\n",
        "):\n",
        "    \"\"\"\n",
        "    This function takes in a Pandas DataFrame and splits the columns\n",
        "    into a target column and a set of predictor variables, i.e. X & y.\n",
        "    These two splits of the data will be used to train a supervised\n",
        "    machine learning model.\n",
        "\n",
        "    :param      data: pd.DataFrame, dataframe containing data for the\n",
        "                      model\n",
        "    :param      target: str (optional), target variable that you want to predict\n",
        "\n",
        "    :return     X: pd.DataFrame\n",
        "                y: pd.Series\n",
        "    \"\"\"\n",
        "    print(\"Creating target and predictor variables...\")\n",
        "    # Print the columns of the DataFrame\n",
        "    print(\"Data columns:\", data.columns)\n",
        "\n",
        "    # Check to see if the target variable is present in the data\n",
        "    if target not in data.columns:\n",
        "        raise Exception(f\"Target: {target} is not present in the data\")\n",
        "\n",
        "    X = data.drop(columns=[target])\n",
        "    y = data[target]\n",
        "    print(\"Target and predictors created successfully\")\n",
        "    return X, y\n",
        "\n",
        "# Train algorithm\n",
        "def train_algorithm_with_cross_validation(\n",
        "    X: pd.DataFrame,\n",
        "    y: pd.Series\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    This function takes the predictor and target variables and\n",
        "    trains a Random Forest Regressor model across K folds. Using\n",
        "    cross-validation, performance metrics will be output for each\n",
        "    fold during training.\n",
        "\n",
        "    :param      X: pd.DataFrame, predictor variables\n",
        "    :param      y: pd.Series, target variable\n",
        "\n",
        "    :return     None\n",
        "    \"\"\"\n",
        "    print(\"Starting cross-validation...\")\n",
        "    # Create a list that will store the accuracies of each fold\n",
        "    accuracy = []\n",
        "\n",
        "    # Enter a loop to run K folds of cross-validation\n",
        "    for fold in range(0, K):\n",
        "        print(f\"Processing fold {fold + 1}...\")\n",
        "        # Instantiate algorithm and scaler\n",
        "        model = RandomForestRegressor()\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        # Create training and test samples\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=SPLIT, random_state=42)\n",
        "\n",
        "        # Scale X data, we scale the data because it helps the algorithm to converge\n",
        "        # and helps the algorithm to not be greedy with large values\n",
        "        # Check if all columns in X_train are numeric before scaling\n",
        "        if all(X_train[col].dtype != 'object' for col in X_train.columns):\n",
        "            scaler.fit(X_train)\n",
        "            X_train = scaler.transform(X_train)\n",
        "            X_test = scaler.transform(X_test)\n",
        "        else:\n",
        "            print(\"Warning: Non-numerical columns detected in X_train. Skipping scaling.\")\n",
        "\n",
        "        # Train model\n",
        "        trained_model = model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate predictions on test sample\n",
        "        y_pred = trained_model.predict(X_test)\n",
        "\n",
        "        # Compute accuracy, using mean absolute error\n",
        "        mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
        "        accuracy.append(mae)\n",
        "        print(f\"Fold {fold + 1}: MAE = {mae:.3f}\")\n",
        "\n",
        "    # Finish\n",
        "     # Finish by computing the average MAE across all folds\n",
        "    print(f\"Average MAE: {(sum(accuracy) / len(accuracy)):.2f}\")\n",
        "\n",
        "# Execute training pipeline\n",
        "def run():\n",
        "    \"\"\"\n",
        "    This function executes the training pipeline of loading the prepared\n",
        "    dataset from a CSV file and training the machine learning model\n",
        "\n",
        "    :param\n",
        "\n",
        "    :return\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the data first\n",
        "    df = load_data(path=\"/content/sales.csv\")\n",
        "\n",
        "    # Now split the data into predictors and target variables\n",
        "    X, y = create_target_and_predictors(data=df)\n",
        "\n",
        "    # Finally, train the machine learning model\n",
        "    train_algorithm_with_cross_validation(X=X, y=y)\n",
        "\n",
        "    run()\n",
        "\n"
      ],
      "metadata": {
        "id": "ngHwDnzRQJPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- 2) DEFINE GLOBAL CONSTANTS\n",
        "K = 10\n",
        "SPLIT = 0.75\n",
        "\n",
        "# --- 3) ALGORITHM CODE\n",
        "\n",
        "# Load data\n",
        "def load_data(path: str = \"/content/sales.csv\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    This function takes a path string to a CSV file and loads it into\n",
        "    a Pandas DataFrame.\n",
        "\n",
        "    :param      path (optional): str, relative path of the CSV file\n",
        "\n",
        "    :return     df: pd.DataFrame\n",
        "    \"\"\"\n",
        "    print(\"Loading data...\")\n",
        "    df = pd.read_csv(f\"{path}\")\n",
        "    df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "    print(\"Data loaded successfully\")\n",
        "    return df\n",
        "\n",
        "# Create target variable and predictor variables\n",
        "def create_target_and_predictors(\n",
        "    data: pd.DataFrame,\n",
        "    target: str = \"category\"\n",
        "):\n",
        "    \"\"\"\n",
        "    This function takes in a Pandas DataFrame and splits the columns\n",
        "    into a target column and a set of predictor variables, i.e. X & y.\n",
        "    These two splits of the data will be used to train a supervised\n",
        "    machine learning model.\n",
        "\n",
        "    :param      data: pd.DataFrame, dataframe containing data for the\n",
        "                      model\n",
        "    :param      target: str (optional), target variable that you want to predict\n",
        "\n",
        "    :return     X: pd.DataFrame\n",
        "                y: pd.Series\n",
        "    \"\"\"\n",
        "    print(\"Creating target and predictor variables...\")\n",
        "    # Print the columns of the DataFrame\n",
        "    print(\"Data columns:\", data.columns)\n",
        "\n",
        "    # Check to see if the target variable is present in the data\n",
        "    if target not in data.columns:\n",
        "        raise Exception(f\"Target: {target} is not present in the data\")\n",
        "\n",
        "    X = data.drop(columns=[target])\n",
        "    y = data[target]\n",
        "    print(\"Target and predictors created successfully\")\n",
        "    return X, y\n",
        "\n",
        "# Train algorithm\n",
        "def train_algorithm_with_cross_validation(\n",
        "    X: pd.DataFrame,\n",
        "    y: pd.Series\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    This function takes the predictor and target variables and\n",
        "    trains a Random Forest Regressor model across K folds. Using\n",
        "    cross-validation, performance metrics will be output for each\n",
        "    fold during training.\n",
        "\n",
        "    :param      X: pd.DataFrame, predictor variables\n",
        "    :param      y: pd.Series, target variable\n",
        "\n",
        "    :return     None\n",
        "    \"\"\"\n",
        "    print(\"Starting cross-validation...\")\n",
        "    # Create a list that will store the accuracies of each fold\n",
        "    accuracy = []\n",
        "\n",
        "    # Enter a loop to run K folds of cross-validation\n",
        "    for fold in range(0, K):\n",
        "        print(f\"Processing fold {fold + 1}...\")\n",
        "        # Instantiate algorithm and scaler\n",
        "        model = RandomForestRegressor()\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        # Create training and test samples\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=SPLIT, random_state=42)\n",
        "\n",
        "        # Scale X data, we scale the data because it helps the algorithm to converge\n",
        "        # and helps the algorithm to not be greedy with large values\n",
        "        # Check if all columns in X_train are numeric before scaling\n",
        "        if all(X_train[col].dtype != 'object' for col in X_train.columns):\n",
        "            scaler.fit(X_train)\n",
        "            X_train = scaler.transform(X_train)\n",
        "            X_test = scaler.transform(X_test)\n",
        "        else:\n",
        "            print(\"Warning: Non-numerical columns detected in X_train. Skipping scaling.\")\n",
        "\n",
        "        # Train model\n",
        "        trained_model = model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate predictions on test sample\n",
        "        y_pred = trained_model.predict(X_test)\n",
        "\n",
        "        # Compute accuracy, using mean absolute error\n",
        "        mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
        "        accuracy.append(mae)\n",
        "        print(f\"Fold {fold + 1}: MAE = {mae:.3f}\")\n",
        "\n",
        "    # Finish\n",
        "     # Finish by computing the average MAE across all folds\n",
        "    print(f\"Average MAE: {(sum(accuracy) / len(accuracy)):.2f}\")\n",
        "\n",
        "# Execute training pipeline\n",
        "def run():\n",
        "    \"\"\"\n",
        "    This function executes the training pipeline of loading the prepared\n",
        "    dataset from a CSV file and training the machine learning model\n",
        "\n",
        "    :param\n",
        "\n",
        "    :return\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the data first\n",
        "    df = load_data()\n",
        "\n",
        "    # Now split the data into predictors and target variables\n",
        "    X, y = create_target_and_predictors(data=df)\n",
        "\n",
        "    # Finally, train the machine learning model\n",
        "    train_algorithm_with_cross_validation(X=X, y=y)\n",
        "\n",
        "run()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "Fwo2NekdTGS3",
        "outputId": "0cb867fa-9d47-488d-adf8-5f04a3820b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Data loaded successfully\n",
            "Creating target and predictor variables...\n",
            "Data columns: Index(['transaction_id', 'timestamp', 'product_id', 'category',\n",
            "       'customer_type', 'unit_price', 'quantity', 'total', 'payment_type'],\n",
            "      dtype='object')\n",
            "Target and predictors created successfully\n",
            "Starting cross-validation...\n",
            "Processing fold 1...\n",
            "Warning: Non-numerical columns detected in X_train. Skipping scaling.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'fcf55ad0-c877-44f5-8c6f-8d00667b5718'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-bc609b4adddf>\u001b[0m in \u001b[0;36m<cell line: 135>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mtrain_algorithm_with_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-bc609b4adddf>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Finally, train the machine learning model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mtrain_algorithm_with_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-bc609b4adddf>\u001b[0m in \u001b[0;36mtrain_algorithm_with_cross_validation\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# Generate predictions on test sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         if (\n\u001b[1;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'fcf55ad0-c877-44f5-8c6f-8d00667b5718'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------- BEFORE STARTING - SOME BASIC TIPS\n",
        "# You can add a comment within a Python file by using a hashtag '#'\n",
        "# Anything that comes after the hashtag on the same line, will be considered\n",
        "# a comment and won't be executed as code by the Python interpreter.\n",
        "\n",
        "# --- 1) IMPORTING PACKAGES\n",
        "# The first thing you should always do in a Python file is to import any\n",
        "# packages that you will need within the file. This should always go at the top\n",
        "# of the file\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- 2) DEFINE GLOBAL CONSTANTS\n",
        "# Constants are variables that should remain the same througout the entire running\n",
        "# of the module. You should define these after the imports at the top of the file.\n",
        "# You should give global constants a name and ensure that they are in all upper\n",
        "# case, such as: UPPER_CASE\n",
        "\n",
        "# K is used to define the number of folds that will be used for cross-validation\n",
        "K = 10\n",
        "\n",
        "# Split defines the % of data that will be used in the training sample\n",
        "# 1 - SPLIT = the % used for testing\n",
        "SPLIT = 0.75\n",
        "\n",
        "# --- 3) ALGORITHM CODE\n",
        "# Next, we should write our code that will be executed when a model needs to be\n",
        "# trained. There are many ways to structure this code and it is your choice\n",
        "# how you wish to do this. The code in the 'module_helper.py' file will break\n",
        "# the code down into independent functions, which is 1 option.\n",
        "# Include your algorithm code in this section below:\n",
        "\n",
        "# Load data\n",
        "def load_data(path: str = \"/content/sales.csv\"):\n",
        "    \"\"\"\n",
        "    This function takes a path string to a CSV file and loads it into\n",
        "    a Pandas DataFrame.\n",
        "\n",
        "    :param      path (optional): str, relative path of the CSV file\n",
        "\n",
        "    :return     df: pd.DataFrame\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(f\"{path}\")\n",
        "    df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "    return df\n",
        "# Create target variable and predictor variables\n",
        "def create_target_and_predictors(\n",
        "    data: pd.DataFrame = None,\n",
        "    target: str = \"category\"\n",
        "):\n",
        "    \"\"\"\n",
        "    This function takes in a Pandas DataFrame and splits the columns\n",
        "    into a target column and a set of predictor variables, i.e. X & y.\n",
        "    These two splits of the data will be used to train a supervised\n",
        "    machine learning model.\n",
        "\n",
        "    :param      data: pd.DataFrame, dataframe containing data for the\n",
        "                      model\n",
        "    :param      target: str (optional), target variable that you want to predict\n",
        "\n",
        "    :return     X: pd.DataFrame\n",
        "                y: pd.Series\n",
        "    \"\"\"\n",
        "\n",
        "    # Check to see if the target variable is present in the data\n",
        "    if target not in data.columns:\n",
        "        raise Exception(f\"Target: {target} is not present in the data\")\n",
        "\n",
        "    X = data.drop(columns=[target])\n",
        "    y = data[target]\n",
        "    return X, y\n",
        "\n",
        "# Train algorithm\n",
        "def train_algorithm_with_cross_validation(\n",
        "    X: pd.DataFrame = None,\n",
        "    y: pd.Series = None\n",
        "):\n",
        "    \"\"\"\n",
        "    This function takes the predictor and target variables and\n",
        "    trains a Random Forest Regressor model across K folds. Using\n",
        "    cross-validation, performance metrics will be output for each\n",
        "    fold during training.\n",
        "\n",
        "    :param      X: pd.DataFrame, predictor variables\n",
        "    :param      y: pd.Series, target variable\n",
        "\n",
        "    :return\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a list that will store the accuracies of each fold\n",
        "    accuracy = []\n",
        "\n",
        "    # Enter a loop to run K folds of cross-validation\n",
        "    for fold in range(0, K):\n",
        "\n",
        "        # Instantiate algorithm and scaler\n",
        "        model = RandomForestRegressor()\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        # Create training and test samples\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=SPLIT, random_state=42)\n",
        "\n",
        "        # Scale X data, we scale the data because it helps the algorithm to converge\n",
        "        # and helps the algorithm to not be greedy with large values\n",
        "        scaler.fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        scaler.fit(y_train)\n",
        "        y_train = scaler.transform(y_train)\n",
        "        y_test = scaler.transform(y_test)\n",
        "\n",
        "        # Train model\n",
        "        trained_model = model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate predictions on test sample\n",
        "        y_pred = trained_model.predict(X_test)\n",
        "\n",
        "        # Compute accuracy, using mean absolute error\n",
        "        mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
        "        accuracy.append(mae)\n",
        "        print(f\"Fold {fold + 1}: MAE = {mae:.3f}\")\n",
        "\n",
        "    # Finish by computing the average MAE across all folds\n",
        "    print(f\"Average MAE: {(sum(accuracy) / len(accuracy)):.2f}\")\n",
        "\n",
        "# --- 4) MAIN FUNCTION\n",
        "# Your algorithm code should contain modular code that can be run independently.\n",
        "# You may want to include a final function that ties everything together, to allow\n",
        "# the entire pipeline of loading the data and training the algorithm to be run all\n",
        "# at once\n",
        "\n",
        "# Execute training pipeline\n",
        "def run():\n",
        "    \"\"\"\n",
        "    This function executes the training pipeline of loading the prepared\n",
        "    dataset from a CSV file and training the machine learning model\n",
        "\n",
        "    :param\n",
        "\n",
        "    :return\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the data first\n",
        "    df = load_data(\"/content/sales.csv\")\n",
        "\n",
        "    # Now split the data into predictors and target variables\n",
        "    X, y = create_target_and_predictors(data=df)\n",
        "\n",
        "    # Finally, train the machine learning model\n",
        "    train_algorithm_with_cross_validation(X=X, y=y)\n"
      ],
      "metadata": {
        "id": "6t7_1qSZVfrJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}